<!doctype html><html><title>Artificial Intelligence</title><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><meta name=apple-mobile-web-app-capable content="yes"><link rel=stylesheet href=https://hermanhel.github.io/braindump/css/main.min.291920189b1189fd3388c38fd9e8ccbdf24640f05f020c32e3da5ba83f9bd5d8.css><body><header><a href=/ id=logo><svg id="Capa_1" enable-background="new 0 0 511.992 511.992" height="512" viewBox="0 0 511.992 511.992" width="512" xmlns="http://www.w3.org/2000/svg"><g><g><g><path d="m256 420.826c0 38.345-11.844 68.545-49.991 68.014-27.744-.385-51.481-15.31-61.853-39.46-1.239-2.887-4.024-4.734-7.154-4.725-.07.0-.135.0-.201.0-47.474.0-75.537-26.171-75.537-73.882.0-5.633.542-11.138 1.568-16.468.62-3.229-.825-6.489-3.671-8.125C23.668 325.748 10 300.053 10 255.997c0-44.057 13.668-69.757 49.161-90.185 2.846-1.636 4.291-4.896 3.671-8.13-1.026-5.33-1.568-10.83-1.568-16.463.0-47.711 28.064-73.882 75.537-73.882h.201c3.13.009 5.915-1.837 7.154-4.729 10.372-24.145 34.109-39.069 61.853-39.455C244.159 22.621 256 52.821 256 91.166" fill="#ff9eb1"/></g><g><g><g><path d="m256 91.166c0-38.344 11.844-68.545 49.991-68.014 27.744.385 51.481 15.31 61.853 39.46 1.239 2.887 4.024 4.734 7.154 4.724h.201c47.474.0 75.537 26.171 75.537 73.882.0 5.633-.542 11.138-1.568 16.468-.62 3.229.825 6.489 3.671 8.125C488.332 186.245 502 211.939 502 255.996s-13.668 69.756-49.161 90.185c-2.846 1.636-4.291 4.896-3.671 8.13 1.026 5.33 1.568 10.83 1.568 16.463.0 47.711-28.064 73.882-75.537 73.882h-.201c-3.13-.009-5.915 1.837-7.154 4.729-10.372 24.145-34.109 39.069-61.853 39.455-38.15.531-49.991-29.669-49.991-68.014" fill="#ff7d97"/></g></g><g><g><path d="m502 265.996c-4.193.0-7.984-2.713-9.407-6.636-1.419-3.912-.16-8.459 3.063-11.092 3.291-2.689 8.009-2.99 11.621-.758 3.568 2.205 5.404 6.578 4.478 10.669-1.02 4.501-5.126 7.817-9.755 7.817z"/></g></g></g><g><path d="m340.83 229.18h-58.013v-58.014h-53.634v58.014H171.17v53.633h58.013v58.013h53.634v-58.013h58.013z" fill="#faf7f5"/></g></g><g><g><path d="m498.468 291.859c-5.141-2.02-10.945.508-12.965 5.648-6.442 16.389-18.055 28.727-37.649 40.005-6.513 3.746-9.932 11.253-8.505 18.689.921 4.783 1.388 9.686 1.388 14.572.0 41.792-22.662 63.882-65.537 63.882h-.225c-.938.0-1.864.074-2.771.217-15.031-4.92-23.796-20.93-19.661-36.479 1.42-5.337-1.757-10.815-7.094-12.234-5.333-1.418-10.814 1.756-12.234 7.094-5.958 22.405 4.241 45.396 23.384 56.443-9.583 17.791-28.602 28.836-50.748 29.145-11.303.146-19.802-2.743-26.011-8.867-9.184-9.057-13.84-25.592-13.84-49.148v-70h16.816c5.522.0 10-4.477 10-10v-48.014h48.014c5.522.0 10-4.477 10-10V229.18c0-5.523-4.478-10-10-10h-48.014v-48.014c0-5.523-4.478-10-10-10H266v-70c0-23.555 4.657-40.09 13.841-49.148 6.21-6.123 14.696-9.022 26.011-8.867 23.862.332 44.096 13.132 52.803 33.405.218.509.458 1.003.719 1.483-3.225 8.243-9.084 15.093-16.833 19.574-8.993 5.2-19.465 6.581-29.485 3.89-5.337-1.434-10.819 1.73-12.251 7.064-1.433 5.334 1.729 10.819 7.063 12.252 5.074 1.363 10.221 2.037 15.338 2.037 10.2.0 20.272-2.681 29.346-7.928 11.083-6.408 19.607-16.017 24.616-27.575 41.6.67 63.569 22.718 63.569 63.866.0 4.89-.467 9.794-1.389 14.582-1.427 7.426 1.991 14.933 8.502 18.678 19.572 11.267 31.176 23.584 37.625 39.936 1.552 3.934 5.318 6.334 9.306 6.333 1.221.0 2.462-.225 3.666-.7 5.138-2.026 7.66-7.834 5.634-12.972-7.943-20.141-22.201-35.773-44.801-49.086.967-5.521 1.457-11.155 1.457-16.772.0-52.114-31.48-83.391-84.288-83.876-12.157-26.863-38.963-43.753-70.318-44.189-16.67-.232-30.255 4.688-40.332 14.625-3.813 3.76-7.08 8.226-9.797 13.382-2.717-5.156-5.984-9.622-9.797-13.382-10.075-9.937-23.668-14.852-40.333-14.625-31.353.437-58.158 17.325-70.32 44.189-52.807.485-84.286 31.762-84.286 83.876.0 5.617.49 11.253 1.458 16.771-37.422 22.031-52.724 50.552-52.724 98.008.0 47.451 15.299 75.969 52.721 98.006-.967 5.521-1.457 11.154-1.457 16.772.0 52.114 31.48 83.391 84.288 83.876 12.157 26.863 38.963 43.753 70.318 44.189.377.005.751.008 1.125.008 16.172.0 29.358-4.92 39.207-14.632 3.813-3.76 7.08-8.226 9.797-13.382 2.717 5.156 5.984 9.622 9.797 13.382 9.849 9.713 23.034 14.633 39.208 14.632.373.0.749-.003 1.125-.008 31.352-.436 58.158-17.325 70.32-44.189 52.807-.485 84.286-31.762 84.286-83.876.0-5.617-.49-11.253-1.458-16.772 22.634-13.329 36.901-28.989 44.838-49.178 2.022-5.14-.507-10.945-5.647-12.966zM282.816 239.18h48.014v33.633h-48.014c-5.522.0-10 4.477-10 10v48.014h-33.633v-48.014c0-5.523-4.477-10-10-10H181.17V239.18h48.014c5.523.0 10-4.477 10-10v-48.014h33.633v48.014c-.001 5.523 4.477 10 9.999 10zm-50.657 230.794c-6.21 6.124-14.717 9.018-26.011 8.867-23.862-.331-44.096-13.132-52.803-33.405-.218-.509-.458-1.003-.719-1.483 3.225-8.243 9.085-15.093 16.833-19.574 8.992-5.2 19.463-6.581 29.485-3.89 5.337 1.434 10.819-1.73 12.251-7.064 1.433-5.333-1.73-10.819-7.064-12.251-15.188-4.08-31.059-1.988-44.684 5.891-11.083 6.408-19.607 16.017-24.616 27.575-41.6-.67-63.569-22.718-63.569-63.866.0-4.89.467-9.794 1.389-14.582 1.427-7.427-1.991-14.934-8.502-18.678-32.183-18.528-44.149-40.621-44.149-81.517.0-40.9 11.966-62.994 44.146-81.517 6.513-3.746 9.932-11.253 8.505-18.689-.921-4.783-1.388-9.686-1.388-14.572.0-41.792 22.662-63.882 65.537-63.882h.225c.938.0 1.864-.074 2.771-.217 15.031 4.92 23.796 20.93 19.661 36.479-1.42 5.337 1.757 10.815 7.094 12.234.861.229 1.726.338 2.577.338 4.422.0 8.467-2.956 9.657-7.432 5.958-22.405-4.241-45.396-23.384-56.443 9.583-17.791 28.602-28.836 50.748-29.145 11.267-.15 19.801 2.743 26.011 8.867 9.184 9.057 13.84 25.592 13.84 49.148v70h-16.816c-5.522.0-10 4.477-10 10v48.014H171.17c-5.522.0-10 4.477-10 10v53.633c0 5.523 4.478 10 10 10h48.014v48.014c0 5.523 4.478 10 10 10H246v70c0 23.554-4.657 40.09-13.841 49.147z"/><path d="m139.699 228.227c-6.766.0-13.186 1.514-18.907 4.31-3.049-8.65-8.286-16.485-15.336-22.673-4.151-3.643-10.469-3.233-14.113.918-3.643 4.15-3.232 10.469.918 14.112 6.711 5.891 10.816 14.143 11.498 22.953-1.213 1.914-2.293 3.946-3.225 6.088-1.145 2.633-2.015 5.316-2.615 8.019-13.414 11.422-33.601 10.834-46.225-1.792-3.906-3.904-10.236-3.904-14.143.0-3.905 3.905-3.905 10.237.0 14.143 10.524 10.524 24.354 15.784 38.193 15.784 8.04.0 16.083-1.775 23.484-5.325 1.904 5.443 4.967 10.557 9.136 15.03.596.639 1.204 1.269 1.826 1.891 1.953 1.953 4.512 2.929 7.071 2.929 2.56.0 5.118-.976 7.071-2.929 3.905-3.905 3.905-10.237.0-14.143-.458-.458-.906-.922-1.342-1.389-6.26-6.716-7.799-15.778-4.118-24.241 2.878-6.616 9.86-13.686 20.826-13.686 5.522.0 10-4.477 10-10 .001-5.522-4.476-9.999-9.999-9.999z"/><path d="m387.667 287.543c-3.905 3.905-3.905 10.237.0 14.143 1.953 1.953 4.512 2.929 7.071 2.929s5.118-.976 7.071-2.929c.622-.622 1.23-1.253 1.83-1.896 4.167-4.471 7.229-9.583 9.133-15.025 7.401 3.549 15.444 5.324 23.484 5.324 13.839.0 27.67-5.261 38.193-15.784 3.905-3.905 3.905-10.237.0-14.143-3.906-3.904-10.236-3.904-14.143.0-12.624 12.625-32.811 13.214-46.225 1.792-.6-2.702-1.47-5.386-2.615-8.019-.932-2.142-2.012-4.175-3.225-6.088.682-8.81 4.787-17.062 11.498-22.953 4.15-3.644 4.561-9.962.918-14.112-3.646-4.151-9.964-4.563-14.113-.918-7.05 6.189-12.287 14.023-15.336 22.673-5.721-2.796-12.141-4.31-18.907-4.31-5.523.0-10 4.477-10 10s4.477 10 10 10c10.966.0 17.948 7.07 20.826 13.686 3.681 8.463 2.142 17.525-4.114 24.237-.44.47-.888.935-1.346 1.393z"/></g></g></g></svg></a><h3 class=site-title>Herman's Place</h3><form id=search action=https://hermanhel.github.io/braindump/search/ method=get><label hidden for=search-input>Search site</label>
<input type=text id=search-input name=query placeholder="Type here to search">
<input type=submit value=search></form></header><div class=grid-container><div class=grid><div class=page data-level=1><div class=content><h1>Artificial Intelligence</h1><p>Guide page to various AI-related topics</p><h2 id=categories>Categories</h2><h3 id=herman-s-categories>Herman&rsquo;s categories</h3><h4 id=expert-system>Expert System</h4><p><a href=https://en.wikipedia.org/wiki/Expert_system>wikipedia</a>
use knowledge and processes an expert would have. Pretty much every algorithm.</p><h4 id=learning>Learning</h4><p>use standards to evolve by the system itself.</p><ul><li><p>supervised learning</p><p>with correct answer(label)</p></li></ul><ul><li><p>unsupervised learning</p><p>without correct answer</p></li></ul><h3 id=ray-dalio-s-categories>Ray Dalio&rsquo;s categories</h3><h4 id=expert-system>Expert System</h4><p>algorithms/machines formulated from 5 step process coded into computer.</p><h4 id=pattern-finding>Pattern finding</h4><p>find pattern in the facts by itself</p><h4 id=data-mining>Data Mining</h4><p>reveal view of the world inside 1 particular large bunch of data.</p><h2 id=math-prerequisites>Math prerequisites</h2><h3 id=linear-algebra--20220423190558-linear-algebra-dot-md><a href=/braindump/main/20220423190558-linear_algebra/>Linear Algebra</a></h3><h4 id=matrix-decomposition>matrix decomposition</h4><p>data comes as matrix.</p><table><thead><tr><th>id</th><th>feature1</th><th>feature2</th></tr></thead><tbody><tr><td>1</td><td>4</td><td>2.72</td></tr><tr><td>2</td><td>5</td><td>1.61</td></tr></tbody></table><p>1 matrix have various properties inside its strucutre. Matrix decomposition describes methods that explicitify the properties.</p><ul><li>Determinant</li></ul><ul><li>Eigenvalues/Eigenvectors</li></ul><ul><li><p>Sigular Value Decomposition(SVD)</p><figure><img src=/Users/hermanhe/Notes/RoamNotes/resource/svd.png width=600px></figure><ul><li>U: orthogonal matrix</li><li>v: orthogonal matrix</li><li>\(\): diagnal matrix. filled with singular values</li></ul><ul><li><p>seeing the results</p><ul><li><p>U: important patterns</p><p>as the \(\) is in descending order, column vectors \(u_{i}\) in \(U\) are in desc order by importance evaluated by singular values in \(/\)</p></li></ul><ul><li>\(\) weights</li></ul><ul><li></li></ul></li></ul><ul><li>computing SVD</li></ul></li></ul><ul><li><p>Principle Component Analysis(PCA)</p><p>Finding \(n\) principle components (column ) in the matrix</p></li></ul><ul><li><p>Independent Component Analysis(ICA)</p><p>seperate mixed signals</p></li></ul><ul><li>Non-Negative Matrix Factorization(NMF)</li></ul><h4 id=continuous-optimization>continuous optimization</h4><ul><li><p>sovlable</p><ul><li>least-square</li><li>linear programming</li><li>convex optimization</li></ul></li></ul><h4 id=gradient-descent>gradient descent</h4><h4 id=constrained-optimization>constrained optimization</h4><h4 id=convex-optimization>convex optimization</h4><h3 id=probabilistic-model>probabilistic model</h3><p>distribution and stuff</p><h4 id=discrete-probabilities>discrete probabilities</h4><h4 id=continuous-probabilities>continuous probabilities</h4><ul><li>probability density function</li></ul><h4 id=gaussian-distribution>Gaussian Distribution</h4><h4 id=conditional-probability>conditional probability</h4><h4 id=baye-s-therorem>Baye&rsquo;s therorem</h4><p>most important formula in all of probability</p><h2 id=data-preprocessing>Data Preprocessing</h2><p>Prepare input for the program to prevent errors/low performance</p><h3 id=bad-value>bad value</h3><p>some values are input wrongly, like a 1000C water temperature</p><h3 id=bad-entry>bad entry</h3><p>very outliners should be excluded from cirtain classes.</p><h3 id=bad-distribution-scale>bad distribution/scale</h3><p>some algorithms do better on a cirtain value range, like [-1,1]. some assume standard distribution. Scaling/normalizing the data to such range boost performance/enable algorithm to run.</p><h3 id=better-features>better features</h3><h3 id=data-analytics>data analytics</h3><h4 id=data-analysis>data analysis</h4><ul><li><p>frequency distribution</p><ul><li>normal distribution</li></ul></li></ul><ul><li>pointiness</li></ul><ul><li>lack of symmetry</li></ul><ul><li><p>centrality</p><ul><li>mean</li></ul><ul><li>median</li></ul><ul><li>mode</li></ul></li></ul><ul><li><p>dispersion</p><ul><li>range</li></ul><ul><li>interquartile range</li></ul><ul><li>variance</li></ul><ul><li>standard deviation</li></ul></li></ul><h4 id=diagnostic-analytics>diagnostic analytics</h4><p>find possible relations</p><ul><li>correlation</li></ul><ul><li>Peawrson&rsquo;s r correlation</li></ul><h4 id=prescriptive-analytics>prescriptive analytics</h4><h4 id=exploratory-analysis>exploratory analysis</h4><p>to find some questions(relations) to explore</p><h4 id=mechanistic-analysis>mechanistic analysis</h4><p>how change in <code>x</code> result in change in <code>y</code>.
tool: regression.</p><h2 id=carrier-of-algorithms>Carrier of algorithms</h2><h3 id=languages>Languages</h3><p>any language, but cirtain languages have special libs/functionalities comes in handy</p><ul><li>python: very many libraries</li><li>R</li><li>java</li><li>c/c++</li><li>Lisp(scheme,common-lisp,clojure)</li></ul><h3 id=platforms>platforms</h3><h4 id=python>python</h4><ul><li>pytorch libs</li><li>sklearn libs: implementation of various learning algorithms/tests</li><li>numpy/matplotlib/pandas libs: basic science computing utils</li><li>tensorflow</li></ul><h2 id=machine-learning>Machine learning</h2><h3 id=mathematical-regression-classification>Mathematical regression/classification</h3><h3 id=classifer-training-via-gradient-descent>Classifer training via gradient descent</h3><h3 id=supervised-learning-algorithms>supervised learning algorithms</h3><p>predict a value. use label.</p><h4 id=classification>classification</h4><ul><li><p>Support Vector Machine</p><ul><li>hyperplane</li></ul><ul><li>Support vector</li></ul><ul><li><p>kernel functions</p><p>make the data points linear separable</p></li></ul><ul><li><p>Multiple classes</p><ul><li>1 vs 1</li></ul><ul><li>1 vs Many</li></ul><ul><li>Many vs Many</li></ul></li></ul></li></ul><ul><li><p>Naive Bayes</p><ul><li>Bayes' Rule</li></ul><ul><li><p>use Bayes' Rule for classification: MAP estimation</p><p>MAP: Maximum a posteriori estimation</p></li></ul><ul><li><p>Naive Bayes Classifier</p><p>the system</p></li></ul></li></ul><ul><li><p>Model likelihood</p><ul><li>log-likelihood</li></ul><ul><li>bayesian estimation & laplacian correction</li></ul><ul><li>Likelihood & Cross Validation & Entropy Measures</li></ul></li></ul><ul><li>Parametric/non-parametric methods</li></ul><ul><li><p>Decision Tree</p><ul><li><p>select attributes</p><ul><li>entropy gain</li></ul><ul><li>ratio gain</li></ul><ul><li>Gini index(CART)</li></ul></li></ul><ul><li>Overfitting</li></ul><ul><li>Random Forest</li></ul></li></ul><ul><li>kNN</li></ul><h4 id=regression>regression</h4><ul><li><p>linear regression</p><ul><li>least square</li></ul><ul><li>multiple linear regression</li></ul><ul><li>how clever is the model.</li></ul><ul><li>model selection</li></ul><ul><li><p>outliers</p><ul><li>spot outliner: cook&rsquo;s distance</li></ul></li></ul></li></ul><ul><li>polynomial regression</li></ul><ul><li><p>logistic regression</p><p>for classification
map data to a probability</p><ul><li><p>alternative funcitons</p><ul><li>Softmax</li><li>tanh</li></ul></li></ul></li></ul><h3 id=unsupervised-learning-algorithms>unsupervised learning algorithms</h3><p>don&rsquo;t predict a value. use no label</p><h4 id=clustering>clustering</h4><ul><li><p>hierachical clustering</p><p>agglomerative clustering (bottom-up)</p><ul><li>algorithm</li></ul><ul><li><p>group strategy</p><ul><li>single linkage</li></ul><ul><li>complete linkage</li></ul><ul><li>average linkage</li></ul></li></ul></li></ul><ul><li><p>k-means</p><p>divisive clustering (top-down)</p><ul><li>algorithm</li></ul><ul><li>k = ?</li></ul></li></ul><ul><li><p>model based clustering</p><ul><li><p>Gaussian Mixture Model</p><ul><li>definition</li></ul><ul><li><p>Expectation Maximisation</p><p>ref: section 11.4, Machine Learning â€“ A Probabilistic Perspective by Keven P. Murphy, the MIT Press</p><ul><li>expectation step</li></ul><ul><li>maximmisation step</li></ul></li></ul></li></ul></li></ul><ul><li><p>performance evaluation</p><p>smaller intra-cluster distance, larger inter-cluster distance
<a href=https://scikit-learn.org/stable/modules/clustering.html#clustering-performance-evaluation>sklearn module</a></p><ul><li>Davies-Bouldin Index</li><li>Calinski-Harabasz Index</li><li>Silhouette Coefficient</li><li>Homogeneity & Completeness</li><li>Fowlkes-Mallows Scores</li></ul></li></ul><ul><li><p>Distance mesurements</p><p><a href=https://www.mathworks.com/help/stats/pdist.html#mw_238ce485-9126-46a1-beaa-f2dcc12573eb>mathwork list</a></p><ul><li>Euclidean Distance</li><li>City Block Distance</li><li>Mahalanobis Distance</li><li>Correlation Distance</li><li>Cosine Distance</li><li>Hamming Distance</li><li>Chebyshev Distance</li><li>Spearman Distance</li><li>Jaccard Distance</li></ul></li></ul><h4 id=density-estimation>density estimation</h4><h2 id=some-application>some application</h2><h3 id=computer-vision>computer vision</h3><h3 id=natural-language-processing>Natural Language Processing</h3><h3 id=machine-learning>machine learning</h3></div><div class=bl-section><h4>Links to this note</h4><div class=backlinks><ul><li><a href=/braindump/daily/2022-04-18/>2022-04-18</a></li></ul></div></div></div></div></div><script src=https://hermanhel.github.io/braindump/js/URI.js type=text/javascript></script><script src=https://hermanhel.github.io/braindump/js/page.js type=text/javascript></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></body></html>